import logging
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from kubernetes import client, config, dynamic
from kubernetes.client import ApiClient
import pandas as pd
import os

# ==============================================================================
# CONFIGURATION & INITIALIZATION
# ==============================================================================

# Configure logging
logging.basicConfig(
    filename="k8s_unused_resources.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

# Load Kubernetes configuration (from ~/.kube/config or in-cluster config)
config.load_kube_config()

# Initialize API clients
v1 = client.CoreV1Api()
apps_v1 = client.AppsV1Api()
batch_v1 = client.BatchV1Api()
rbac_v1 = client.RbacAuthorizationV1Api()
networking_v1 = client.NetworkingV1Api()
apiextensions_v1 = client.ApiextensionsV1Api()
storage_v1 = client.StorageV1Api()
dynamic_client = dynamic.DynamicClient(ApiClient())

# ==============================================================================
# HELPER FUNCTIONS
# ==============================================================================

def get_namespaces():
    """
    Returns the list of namespaces to scan.
    If a file named "namespaces.txt" exists, uses its content.
    Otherwise, returns all namespaces.
    """
    if os.path.exists("namespaces.txt"):
        with open("namespaces.txt", "r") as f:
            namespaces = [line.strip() for line in f.readlines() if line.strip()]
        logging.info(f"Scanning namespaces (from file): {namespaces}")
        return namespaces
    else:
        ns_list = [ns.metadata.name for ns in v1.list_namespace().items]
        logging.info(f"No namespaces.txt found. Scanning all namespaces: {ns_list}")
        return ns_list

NAMESPACES = get_namespaces()

# ==============================================================================
# UNUSED RESOURCE DETECTION FUNCTIONS (HEURISTICS)
# ==============================================================================

def find_unused_pvs():
    """Unused PersistentVolumes are those in the 'Available' phase (not bound)."""
    try:
        pvs = v1.list_persistent_volume().items
        unused = [pv.metadata.name for pv in pvs if pv.status.phase == "Available"]
        return unused
    except Exception as e:
        logging.error(f"Error in find_unused_pvs: {e}")
        return []

def find_unused_pvcs():
    """
    Unused PersistentVolumeClaims: those not in the 'Bound' phase.
    (Pending PVCs may be valid in some cases; adjust as needed.)
    """
    unused = []
    def process_namespace(ns):
        ns_unused = []
        try:
            pvcs = v1.list_namespaced_persistent_volume_claim(ns).items
            for pvc in pvcs:
                if pvc.status.phase != "Bound":
                    ns_unused.append(f"{ns}/{pvc.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_pvcs for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_configmaps_and_secrets():
    """
    Unused ConfigMaps and Secrets are those not referenced by any pod volumes.
    (This scan only inspects podsâ€™ volumes; additional references may be missed.)
    """
    used_configmaps, used_secrets = set(), set()
    def process_namespace(ns):
        local_used_cm, local_used_sec = set(), set()
        try:
            pods = v1.list_namespaced_pod(ns).items
            for pod in pods:
                if pod.spec.volumes:
                    for volume in pod.spec.volumes:
                        if volume.config_map:
                            local_used_cm.add(volume.config_map.name)
                        if volume.secret:
                            local_used_sec.add(volume.secret.secret_name)
        except Exception as e:
            logging.error(f"Error scanning pods in {ns} for ConfigMap/Secret usage: {e}")
        return local_used_cm, local_used_sec

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            cm, sec = future.result()
            used_configmaps.update(cm)
            used_secrets.update(sec)
    try:
        all_configmaps = {cm.metadata.name for cm in v1.list_config_map_for_all_namespaces().items}
        all_secrets = {sec.metadata.name for sec in v1.list_secret_for_all_namespaces().items}
    except Exception as e:
        logging.error(f"Error listing all ConfigMaps/Secrets: {e}")
        return [], []
    unused_configmaps = list(all_configmaps - used_configmaps)
    unused_secrets = list(all_secrets - used_secrets)
    return unused_configmaps, unused_secrets

def find_unused_pods():
    """
    Unused pods are defined as those that have terminated (Succeeded or Failed) or
    those that are not running and older than a threshold (1 hour by default).
    """
    unused = []
    threshold = datetime.utcnow() - timedelta(hours=1)
    def process_namespace(ns):
        ns_unused = []
        try:
            pods = v1.list_namespaced_pod(ns).items
            for pod in pods:
                phase = pod.status.phase
                if phase in ["Succeeded", "Failed"]:
                    ns_unused.append(f"{ns}/{pod.metadata.name}")
                else:
                    creation_ts = pod.metadata.creation_timestamp
                    if creation_ts and creation_ts.replace(tzinfo=None) < threshold and phase != "Running":
                        ns_unused.append(f"{ns}/{pod.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_pods for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_services():
    """
    For Services (ClusterIP, NodePort), check if associated Endpoints are empty.
    (ExternalName services are skipped.)
    """
    unused = []
    def process_namespace(ns):
        ns_unused = []
        try:
            services = v1.list_namespaced_service(ns).items
            for svc in services:
                svc_type = svc.spec.type
                if svc_type == "ExternalName":
                    continue  # skip external services
                try:
                    ep = v1.read_namespaced_endpoints(svc.metadata.name, ns)
                    if not ep.subsets:
                        ns_unused.append(f"{ns}/{svc.metadata.name}")
                except Exception as e:
                    logging.error(f"Error reading endpoints for service {ns}/{svc.metadata.name}: {e}")
                    ns_unused.append(f"{ns}/{svc.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_services for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_deployments():
    """Unused deployments are those with zero desired or zero available replicas."""
    unused = []
    def process_namespace(ns):
        ns_unused = []
        try:
            deps = apps_v1.list_namespaced_deployment(ns).items
            for dep in deps:
                desired = dep.spec.replicas or 0
                available = dep.status.available_replicas or 0
                if desired == 0 or available == 0:
                    ns_unused.append(f"{ns}/{dep.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_deployments for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_statefulsets():
    """Unused statefulsets are those with zero desired replicas."""
    unused = []
    def process_namespace(ns):
        ns_unused = []
        try:
            sts_list = apps_v1.list_namespaced_stateful_set(ns).items
            for sts in sts_list:
                desired = sts.spec.replicas or 0
                if desired == 0:
                    ns_unused.append(f"{ns}/{sts.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_statefulsets for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_daemonsets():
    """Unused daemonsets are those with zero scheduled pods."""
    unused = []
    def process_namespace(ns):
        ns_unused = []
        try:
            ds_list = apps_v1.list_namespaced_daemon_set(ns).items
            for ds in ds_list:
                scheduled = ds.status.current_number_scheduled or 0
                if scheduled == 0:
                    ns_unused.append(f"{ns}/{ds.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_daemonsets for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_replicasets():
    """Unused replicasets are those with zero desired replicas."""
    unused = []
    def process_namespace(ns):
        ns_unused = []
        try:
            rs_list = apps_v1.list_namespaced_replica_set(ns).items
            for rs in rs_list:
                desired = rs.spec.replicas or 0
                if desired == 0:
                    ns_unused.append(f"{ns}/{rs.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_replicasets for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_jobs():
    """
    Unused jobs are those that have either succeeded or failed.
    Unused cronjobs are those not suspended and without a recent schedule.
    """
    unused_jobs = []
    unused_cronjobs = []
    def process_namespace(ns):
        ns_unused_jobs = []
        ns_unused_cronjobs = []
        try:
            jobs = batch_v1.list_namespaced_job(ns).items
            for job in jobs:
                if job.status.succeeded or job.status.failed:
                    ns_unused_jobs.append(f"{ns}/{job.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_jobs for namespace {ns}: {e}")
        try:
            cronjobs = batch_v1.list_namespaced_cron_job(ns).items
            for cj in cronjobs:
                if not cj.spec.suspend and not cj.status.lastScheduleTime:
                    ns_unused_cronjobs.append(f"{ns}/{cj.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_cronjobs for namespace {ns}: {e}")
        return ns_unused_jobs, ns_unused_cronjobs

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            nj, ncj = future.result()
            unused_jobs.extend(nj)
            unused_cronjobs.extend(ncj)
    return unused_jobs, unused_cronjobs

def find_unused_ingresses():
    """
    Unused ingresses are heuristically detected if their referenced services are missing.
    (This is a bestâ€‘effort approach.)
    """
    unused = []
    def process_namespace(ns):
        ns_unused = []
        try:
            ing_list = networking_v1.list_namespaced_ingress(ns).items
            for ing in ing_list:
                backend_missing = False
                if ing.spec.default_backend:
                    svc_name = ing.spec.default_backend.service.name
                    try:
                        v1.read_namespaced_service(svc_name, ns)
                    except Exception:
                        backend_missing = True
                if ing.spec.rules:
                    for rule in ing.spec.rules:
                        if rule.http and rule.http.paths:
                            for path in rule.http.paths:
                                svc_name = path.backend.service.name
                                try:
                                    v1.read_namespaced_service(svc_name, ns)
                                except Exception:
                                    backend_missing = True
                if backend_missing:
                    ns_unused.append(f"{ns}/{ing.metadata.name}")
        except Exception as e:
            logging.error(f"Error in find_unused_ingresses for namespace {ns}: {e}")
        return ns_unused

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            unused.extend(future.result())
    return unused

def find_unused_storageclasses():
    """
    A StorageClass is considered unused if no PVC references it.
    """
    try:
        storage_classes = [sc.metadata.name for sc in storage_v1.list_storage_class().items]
        all_pvcs = []
        for ns in NAMESPACES:
            try:
                pvcs = v1.list_namespaced_persistent_volume_claim(ns).items
                all_pvcs.extend([pvc for pvc in pvcs if pvc.spec.storage_class_name])
            except Exception as e:
                logging.error(f"Error listing PVCs in namespace {ns}: {e}")
        used_sc = {pvc.spec.storage_class_name for pvc in all_pvcs}
        unused = [sc for sc in storage_classes if sc not in used_sc]
        return unused
    except Exception as e:
        logging.error(f"Error in find_unused_storageclasses: {e}")
        return []

def find_unused_serviceaccounts():
    """
    A ServiceAccount is considered unused if not referenced by any pod.
    (This heuristic inspects pod serviceAccountName fields.)
    """
    used_sas = set()
    def process_namespace(ns):
        ns_used = set()
        try:
            pods = v1.list_namespaced_pod(ns).items
            for pod in pods:
                sa = pod.spec.service_account_name or "default"
                ns_used.add(f"{ns}/{sa}")
        except Exception as e:
            logging.error(f"Error scanning pods in {ns} for service account usage: {e}")
        return ns_used

    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(process_namespace, ns): ns for ns in NAMESPACES}
        for future in as_completed(futures):
            used_sas.update(future.result())

    unused = []
    for ns in NAMESPACES:
        try:
            sas = v1.list_namespaced_service_account(ns).items
            for sa in sas:
                key = f"{ns}/{sa.metadata.name}"
                if key not in used_sas:
                    unused.append(key)
        except Exception as e:
            logging.error(f"Error listing service accounts in {ns}: {e}")
    return unused

def find_unused_namespaces():
    """
    Nonâ€‘system namespaces with no pods are flagged as unused.
    (System namespaces like kube-system, kube-public, default, and kube-node-lease are skipped.)
    """
    unused = []
    system_ns = {"kube-system", "kube-public", "default", "kube-node-lease"}
    for ns in NAMESPACES:
        if ns in system_ns:
            continue
        try:
            pods = v1.list_namespaced_pod(ns).items
            if not pods:
                unused.append(ns)
        except Exception as e:
            logging.error(f"Error checking namespace {ns} for pods: {e}")
    return unused

def find_unused_crds():
    """
    For each CustomResourceDefinition, use the dynamic client to determine if any
    custom objects exist. If none are found, the CRD is flagged as unused.
    """
    unused = []
    try:
        crds = apiextensions_v1.list_custom_resource_definition().items
        for crd in crds:
            group = crd.spec.group
            versions = [v.name for v in crd.spec.versions if v.served]
            if not versions:
                continue
            version = versions[0]
            try:
                resource = dynamic_client.resources.get(api_version=f"{group}/{version}", kind=crd.spec.names.kind)
                items = resource.get().items
                if not items:
                    unused.append(crd.metadata.name)
            except Exception as e:
                logging.error(f"Error fetching custom objects for CRD {crd.metadata.name}: {e}")
        return unused
    except Exception as e:
        logging.error(f"Error in find_unused_crds: {e}")
        return []

def find_unused_rbac():
    """
    For RBAC resources, this function collects Roles, RoleBindings, and ClusterRoles.
    A deep dependency analysis of RBAC is complex; here we simply report what exists.
    """
    unused_roles = []
    unused_rolebindings = []
    unused_clusterroles = []
    for ns in NAMESPACES:
        try:
            roles = rbac_v1.list_namespaced_role(ns).items
            unused_roles.extend([f"{ns}/{r.metadata.name}" for r in roles])
            rbs = rbac_v1.list_namespaced_role_binding(ns).items
            unused_rolebindings.extend([f"{ns}/{rb.metadata.name}" for rb in rbs])
        except Exception as e:
            logging.error(f"Error in find_unused_rbac for namespace {ns}: {e}")
    try:
        crs = rbac_v1.list_cluster_role().items
        unused_clusterroles = [cr.metadata.name for cr in crs]
    except Exception as e:
        logging.error(f"Error listing cluster roles: {e}")
    return unused_roles, unused_rolebindings, unused_clusterroles

# ==============================================================================
# REPORTING FUNCTION
# ==============================================================================

def save_results_to_excel(unused_resources):
    """
    Saves the unused resource findings to an Excel workbook.
    Each resource type is saved in its own sheet.
    """
    filename = "unused_k8s_resources.xlsx"
    try:
        with pd.ExcelWriter(filename, engine="xlsxwriter") as writer:
            for resource, items in unused_resources.items():
                if items:
                    # Truncate sheet name to 31 characters (Excel limit)
                    sheet_name = resource[:31]
                    df = pd.DataFrame(items, columns=[f"Unused {resource}"])
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
                    workbook = writer.book
                    worksheet = writer.sheets[sheet_name]
                    cell_format = workbook.add_format({"bold": True, "bg_color": "#FFC7CE"})
                    worksheet.set_column("A:A", 40, cell_format)
        logging.info(f"Results saved to '{filename}'")
    except Exception as e:
        logging.error(f"Error saving Excel file: {e}")

# ==============================================================================
# MAIN SCAN FUNCTION
# ===============================================
